{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "from pytubefix import YouTube\n",
    "import whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class YT_Audio_Downloader:\n",
    "    def __init__(self,url):\n",
    "        self.url = url\n",
    "\n",
    "    def download_audio(self):\n",
    "        try:\n",
    "            yt_audio = YouTube(self.url).streams.get_audio_only()\n",
    "            yt_audio.download()\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "        return yt_audio.default_filename\n",
    "    \n",
    "    def save_to_db(self):\n",
    "        pass\n",
    "\n",
    "class AudioConverter:\n",
    "    def __init__(self,audiopath):\n",
    "        self.audiopath = audiopath\n",
    "\n",
    "    def convert(self):\n",
    "        model = whisper.load_model(\"base\")\n",
    "        result = model.transcribe(self.audiopath)\n",
    "        return result[\"text\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "video = YT_Audio_Downloader(\"https://www.youtube.com/watch?v=46XbjplgwOw\")\n",
    "audio_path = video.download_audio()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Depuis leur introduction, en 2017, les transformeurs ont pris une place très importante au sein du machine learning et depuis l'avènement de chat GPT, ils sont devenus encore plus populaire. Le transformer c'est un type de raison de Neuron qui vient améliorer les raisons de Neuron récurrents, ils sont donc comme les RNN bien adaptés pour traiter des séquences comme du texte. On peut relever deux avancées des transformeurs par rapport au RNN, la première c'est qu'il n'effectue plus de calculs séquanciels et bienvenu être entraînés sur des GPU pour profiter des calculs effectués en parallèle. La seconde avancée, c'est celle du mécanisme d'attention, l'attention en machine learning et c'est la capacité d'un modèle à sélectionner les parties de l'entrée qu'ils pensent intéressantes pour pouvoir effectuer la tâche qu'il a à faire. Comment on va représenter l'entrée du réseau ici une phrase donc une séquence de mots ? Ce qu'on faisait avec les RNN, c'était comparté d'un état de départ H0 quelconque, puis au firm mesure qu'on recevait de nouvelles entrées, les X1, X2, etc. On mettait à jour en quelque sorte notre état caché avec ses entrées. Un problème avec ce mode de fonctionnement, c'est que si on prend le patentant 4 par exemple, toute information vu depuis le départ doit être contenu dans un seul vecteur H4. Et pour de longs séquences, il est alors facile pour le réseau doublier les éléments de la séquence vu il y a longtemps, puisque l'état caché a depuis été perturbé ou modifié par les nouvelles entrées. Alors, quoi cela pose-t-il problème ? Bien prenaux cet exemple particulier de classification, où le réseau doit dire si une phrase est positive ou négative. Ici toute l'information qui indique si cette phrase est positive ou négative se trouve malheureusement en début de phrase. Et donc, il est possible que l'état caché final H9, qui va être utilisé pour faire la prédiction, eh bien, cet a caché est possible qu'il ne contienne plus l'information, c'est-à-dire la présence du mot «bon ». Et donc là, le réseau va être en grande difficulté pour pouvoir prédire la bonne réponse. Alors justement, pour parler à ce problème, on introduit le mécanisme d'attention. Le calcul de H9 avec ce mécanisme, il ne reposera plus sur X9 et H8, mais plutôt sur toutes les entrées précédentes de X1 à X9. Donc là, on voit qu'il va pouvoir utiliser l'entrée X1, le mot «bon », pour faire sa prédiction. Alors, regardons cela avec un exemple plus court pour avoir un petit ou plus de clarté. Alors, on va affecter à chaque entrée 3 victors. En fait, chaque vector d'entrée, donc X1, X2, X3, va donner lieu à 3 victors une cohérie «Q » ou encore appelée « Requête ». Donc un vector qu'on va appeler la « Clé », la « Qui », donc on va noter « K », et une value « V », qui va correspondre à la valeur de l'entrée. Et ces victors, on va les indiquer en fonction de la position dans la séquence d'entrée. Alors, tu es-vimment, cela va nous permettre de comparer les clés, donc les victors « K » avec les cohéries, les « Requettes « Q », ce qui va permettre au modèle de savoir sur quel entrée il va porter son attention. Donc pour calculer H3, on va commencer par comparer la cohérie « A » « Social Entrée 3 », donc Q3, avec les clés des entrées. On va alors obtenir ce qu'on appelle « Les scores d'attention ». Alors, concrètement, pour comparer une requête avec une clé, on peut utiliser un produit scalère, donc plus ce produit scalère, qui est un nombre plus il va aller trélever, et bien plus les victors sont semblables. Donc ces scores d'attention, ce sont des nombre et il y en a un par entrée. Et puis, en score donné les « A », plus le modèle va prendre en compte l'entrée associée à ce score. Donc justement, la dernière étape, avant de calculer H3, c'est de passer ces scores dans une fonction « Soft Max », qui va simplement permettre de normaliser ces scores afin que leur sum va le « A ». Ensuite, on aura donc trois nombre que l'on note de « S1 » à « S3 » avec à chaque fois une parenthèse « 3 » pour indiquer qu'ils ont été calculés pour obtenir H3. Donc on a un score par entrée. On peut alors calculer H3, qui va le voir en fait « S1 » fois « V1 », plus « S2 » fois « V2 », plus « S3 » fois « V3 ». C'est-à-dire que chaque entrée a flu plus ou moins sur H3 en fonction de sa pertinence avec la requête « 3 » et donc avec « X3 ». Donc une entrée qui est très peu pertinente par rapport à la requête « 3 », bien, va avoir un score d'attention proche de « 0 » et, comme on l'a avec cette vermule, ne va donc pas beaucoup compter dans le calcul de H3. Alors on retrouve bien cette idée d'attention. Le modèle sélectionne parmi les entrées, celle qui sont les plus intéressantes pour le calcul de l'Etat caché actuel. Un petit exemple rapide, avec la phrase « Il revient du théâtre », il a vu une pièce magnifique. Au moment du calcul de l'Etat associé à l'entrée « PS », le modèle pour avoir une représentation pertinente du mot « PS », va devoir porter une grande partie de son attention sur le mot « théâtre » qui va lui permettre de comprendre et de donner le bon sens aux mots « PS » dans cette phrase. A noter qu'on a représenté le calcul de H3 seulement, mais au calcul de la même manière, les autres est accachés à chins et à g'eux, avec dans chaque cas la requête qui interroge les clés des entrées précédentes comme on l'a fait pour H3. Donc voici l'essentiel de ce qui est en transformer. Ce qui est intéressant avec sa taxitecture, les calculs peuvent être effectués en parallèle, c'est à dire qu'on peut calculer les Etats cachés à chins H2H3 en parallèle. Par exemple, on l'a vu, H3 ne dépend d'aucun d'État caché précédent, seulement des clés requêtes et valeurs des entrées précédentes. Comme toujours, qui dit calcul en parallèle, dit Mathrice, on va donc regrouper les calculs faits dans des Mathrices. Donc si on note, grand cul, la Mathrice qui regroupe les requêtes des entrées, qui est en cul ne cul 3, en cas celle qui regroupe les clés et grandvis les valeurs, on tombe sur cette fameuse équation. Donc l'attention de cul, cave et t'égal à softmax de cul 4 ans, foie v, ou attention de cul cave, regroupe les Etats cachés H. Alors pour établir cela, on va commencer par écrire la multiplication de cul par 4 ans, ça nous donne 7 Mathrices. On y retrouve donc les scores d'attention non normalisés. Et donc avant d'appliquer le softmax pour les normaliser justement, en fait on se rend compte que ces trois valeurs qui sont au-dessus de la diagonale et bien en fait on en revue pas. Alors pourquoi ? Parce qu'il s'agit d'une comparaison entre une requête et une clé, dont la clé proverne une entrée future à la requête, c'est-à-dire d'une entrée qui se trouve après l'entrée associée à la requête. Par exemple, cuisant Scalert, Q2, l'entrée 2 se trouve bien après l'entrée 1. Et ça, ça va bien, en fait, apprendre en compte pour le calcul de H1, la deuxième entrée, donc une entrée qui apparaît dans le futur. Et en quelque sorte, c'est tricher puisqu'on reçoit de nous entrer, en fait, au fur à mesure dans le temps et donc il faut que l'Etat caché ne dépendent que de ce qu'il y a eu avant. Pour se débarrasser de ces termes, on peut tout simplement ajouter à la Mathrice obtenue Q4, transposée, la Mathrice suivante, on parle de Mathrice, masque, moins l'infinie au-dessus de la diagonale et des 0 en dessous. On obtient alors cette Mathrice sur laquelle on va donc appliquer la fonction softmax. Selon l'axe des lignes, c'est-à-dire l'axe 0, c'est-à-dire l'axe pour lequel la requête est la même. Et là, tous les termes qui valent moins l'infinie grâce à notre masque vont automatiquement valoir 0 après le passage dans softmax. Et donc, au final, on se retrouve avec la Mathrice qui contient les scores d'attention normalisée, les S1, S2, S3, donc qui suffit plus que de la multiplier avec la Mathrice des valeurs et on obtient bien nos Etats cachés. Alors, pas long rapidement, les tailles des Mathrices concernées, grand Q2 taille 3 par DQ, ou DQ et la taille des Vecteurs requêtes, et 3, c'est le nombre d'entrais qui est évidemment variable en fonction de la séquence d'entrée, et cas, et 2 tailles 3 par DQ, la taille donc des Vecteurs clés, et V et 2 tailles 3 par DV, la taille des Vecteurs valeurs. Un dernier détail, pour l'instant, on a perdu la notion d'ordre entre les différentes entrées, c'est-à-dire que par exemple, le modèle ne peut pas faire la différence entre la phrase le chat pour suivre la souris et la souris pour suivre le chat. Alors, en effet, lors des calculs, lors, n'est jamais pris en compte, puisqu'en fait, on ne fait que calculer en parallèle pour tous les entrés, un produit scalaire qui ne dépend pas des positions, mais seulement des mots en eux-mêmes. Alors, à noter que pour le RNN, on n'avait pas ce problème, étant donné que les calculs étaient faits séquantiellement, donc l'ordre était naturellement gardé. Alors, pour remédia-ce-là avec notre transformer, on va ajouter à chaque entrée, donc en fait, en amont du réseau, un vecteur qui va être marqueur de position, et en fait, on va fournir comme entrée, l'ancien entrée, plus ce vecteur de position. Alors on verra ça un peu plus en détail dans une vidéo dédiée, mais cela suffit au modèle de retrouver l'information de la position. Pour finir, on va parler de l'entraînement d'un tel modèle. Alors déjà, quels sont les paramètres entraînables dans ce modèle, il s'agit des matrices qui permettent de passer du vecteur entré aux trois vecteurs associés, donc les vecteurs requêtes, clés et valeurs. Ces matrices, il y en a trois, donc une pour passer de l'entrée aux vecteurs requêtes, une pour avoir la clé et la troisième pour avoir le vecteur valeur. Et donc, il est important noté qu'on utilise à chaque fois ces trois mêmes matrices pour toutes nos entrées. Alors on peut les appeler naturellement, WQ, WK et WV, et cela va être le rôle de l'entraînement de trouver les bons coefficients à mettre dans ces matrices pour que le modèle arrive à effectuer la tâche qu'on souhaite lui faire faire. Alors une petite note sur la taille de ces matrices, WQ et de taille M par DQ, avec je le rappelle donc DQ la taille des vecteurs requêtes et M la taille des vecteurs reçus entrés. Même chose pour WK, de taille M par DQ et WV, de taille M par DV. Donc voilà pour les bases de l'architecture du transformer, je pense que le plus important dans tout ça, c'est de bien comprendre ce schéma qui est vraiment central puisque en fait tout des couleurs de ce schéma que ce soit les équations ou même l'idée, l'intuition de ce qui est la tension. Alors évidemment l'architecture entière ne s'arrête pas là. On va en avoir dans la prochaine vidéo comment rendre ces réseaux plus puissants, et dire à l'heure actuelle leur donner plus de paramètres.\n"
     ]
    }
   ],
   "source": [
    "text = AudioConverter(audio_path).convert()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Bonjour à tous, aujourd'hui on va regarder pourquoi Solana pourrait crash et au repot au répotentiellement, pardon, fait son top. Alors je vous explique tout ceci, on va avoir l'analyse ensemble. On revient sur du Weekly, sur notre ami Solana. Quelque chose de très intéressant, c'est ça. Pour moi ça c'est des structures de top, comme vous le voyez ici, un peu comme là, un peu comme là. Ici déjà ce qu'on a eu, c'est Solana qui a fait une prise de liquidité. Mais ce n'est pas tout. Solana qui est très proche aussi de casser le loup qui maintient sa structure. Ce loup là, selon moi, si il est cassé, c'est un signal baissier sur Solana qui va entraîner un retrasement et selon moi pour écoser un retrasement de Solana jusqu'en dessous des 100 dollars. Ok, je dis 100 dollars, 140, je pense qu'on ira en tout ce niveau là. Donc peut-être que ça serait une centaine de dollars, voire jusqu'à 80, 20 dollars en vion. Alors pour certains ça peut paraître fou, mais je vais vous expliquer le setup et quand est-ce que je mettrai des signos d'alarmes sur notre ami Solana. Déjà il faut savoir que la zone de Solana était intéressante à l'achat. Pour ma part, c'est assez simple, c'était dans ce bloc là. Donc entre une vingtaine et une trentaine de dollars, si vous avez eu l'exébécier pour moi de temps mieux. Voilà, à l'époque on l'avait acheté à 8 dollars pour ma part. J'ai un prix moyen plus autour des 15, ce que j'ai très vite vendu d'ailleurs. Mais là on est quand même sur une performance qui est d'une d'un boule-market et notamment au niveau du market cap. Parce que beaucoup de gens oublient sur notre ami Solana qui a fait un top en fait et qui a fait sa première vague baisseur déjà après le top en market cap. Qui en a refait un et qui a pareil une structure de top selon moi quand on le voit juste ici. Donc alors maintenant si on va sur l'analyse plus court terme qui m'indique qu'on pourrait avoir top, déjà c'est ce que je vois en monthly, c'est ce que je vois en weekly et c'est ce que je vois en daily. C'est quand d'ailey du coup, tout simplement on a eu la prise de liquidité. On a paréliciaque à ce niveau là. Et le moment de temps mais ultra baissier pour l'instant tout est bien respecté à les imbalances. S'en respecter, ok c'est cool. Mais le signal long terme pour moi n'a pas été envoyé pourquoi? Parce que le signal long terme nous indiquait qu'on était toujours aucier, qu'on a réagis dans cette gymaine de là, qu'on a bien évidemment effectué cette réaccumulation. Vous voyez ce que je veux dire? Et que maintenant on est revenu dans la gymaine d'une salle très très cool. Mais pour l'instant on ne semble pas réagir. Pourquoi? Alors je vais vous le dire assez simplement parce que si on l'orda ici, on l'a regardé au niveau du retracement, là on est arrivé dans la dernière zone selon moi sur le solana qui est ici et en 4 cassures de cette zone là selon moi on va aller plus bas. Alors ce qui est faisable en fait à l'heure actuelle sur solana, en tout cas pour ma part, c'est une récupération de ce AI juste ici pour un retour dans la AVG, pour ensuite faire un genre de distribution, je ne sais quoi ou je ne sais quoi. Simplement. Donc pour l'instant, sur du court terme, le momentum est baissier, pour moi on peut revenir jusqu'à ce que c'est à il a. Donc là pour l'instant on ne peut pas trop se positionner sur solana, vous voyez ce que je veux dire. Pour l'instant on a vraiment une structure qui est assez jolie. On reviendra la gymaine d'initial, on rebondit, on retrace le mouvement aussi quand je vous l'ai dit ici, on revient dans les zones de fibonacci, on a une belle réaction pour ma part, il ne faut pas s'enflammer. Par rapport au potentiel top qu'on a eu ici. Ok. Du coup pour moi le signal d'alarm, on va bien le dire du moment sur solana quand on casera ce niveau là. Quand on casera ce niveau là, ce sera assez simple. Pour ma part, ce sera un genre de distribution que sera validée pour ma part et on pourrait bien aller chercher des niveaux plus bas, voir celui-là. Tout c'est l'eau qu'on n'est pas venu chercher pendant tout ce temps-là. Ça se trouve que je vous dis ça, on va juste récupérer ces niveaux là sur solana. On va descendre jusqu'à dans ce bloc là, donc imaginons ce bloc là qu'on avait identifié la cumulation entre 93 et 18. Et ensuite ça suffira peut-être peut-être pas. Mais voilà, en tout cas pour moi, quand je vois une structure de la sorte, tu me fais penser beaucoup à Caspa et elle me fait penser du coup à de la distribution. Ok. Et comme c'est un alcune, je m'attends à ce qu'on vient combler les gâbes qu'on est venus, qu'on est venus créer. Donc bien sûr qu'on peut avoir un rallé aussi sur solana pour des plus hauts, mais pour l'instant la structure me paraît topiche et mon alerte se retrouve ici. Que vous voyez là, je la crée, elle se retrouve ici et pour moi en cas de Caspa sur ce niveau là sur solana, je ne serai plus optimiste sur le projet. Enfin sur le projet, je serai toujours optimiste sur le projet, sur le prix je ne serai plus optimiste. Ok. Très bien on peut avoir des réactions ici, mais pour le moment, momentum repassera baissier et ceci parce que on aura la casseur de se l'eau en wikli. Ok. Vous voyez ce que je veux dire? Ce qu'on a... Comment dire? Ce qu'on a jamais fait encore, parce que tous les l'eau wikli sont respectés. Celui là, celui... Donc là, celui là qui a amené ce AI, celui là qui a amené ce AI, celui là qui a amené ce AI, qui va bientôt être brisé. Ok. Pour moi, du coup, on est très sûr une phase distributive, qui est causerai un retrasement et j'ai l'impression qu'on a ça sur l'ensemble de l'écosystème solana. Si je prends un truc comme Radeium, pour moi, ça ressemble à ce truc là, ça ressemble à une distribution. Ok. Une distribution, pourquoi? Parce que regardez en wikli. En mancli, on est sur un truc qui a fait, je sais pas, qui a fait, fois... Faux 60, fois 62, en très peu temps, depuis... ou 23 jours. Donc même ici, ça... j'ai l'impression qu'on rentre sur un gros pattern de distribution, comme ce qu'on avait eu sur Injective, avec une création de trendline, un excès aussi et ensuite, on revient et comme solana, on est à deux doigts de break, pour moi, on l'abrèque vu les oeuvres et selon moi, du coup, de causer un retrasement. Donc la distribution, ça peut comme je les dirais récupérer la tière, comme ça peut être un retrasement plus profond. Ok. Et ce qu'il faut savoir, c'est que pour moi, quand tu vois cette structure-là, avant de repositionner boule, il faut que t'attente d'une phase d'accumulation, pareil sur solana, pour ma part, si j'aimerais en avoir une cassure ici, je n'aimerais pas à racheter les zones sur solana, à part, si elles sont bas ici, mais je m'attenderai à avoir une consolidation exactement comme ce qu'on a eu ici. Il y a un an, c'était quoi, c'était en 2023, on l'avait très bien identifié celle de solana, on l'avait très bien identifié. Donc une accumulation comme celle-ci, une accumulation comme celle-ci, ok, création d'un support, boom, liquidation pour repartir, une accumulation comme celle-ci, sans cela, pour moi, il faudra pas toucher le truc et même si on a une accumulation d'ailleurs, on peut, on peut, on peut, voilà, une accumulation courtaine, je vous rappelle, on peut faire ça, pump, revenir ici, et en fait, là, on a une accumulation mais courtaine, vous voyez ce que je veux dire ? Donc voilà, donc pour ma part, ça peut être un signal très très baissé, notamment comme ce que je vois, du coup, sur solana, mais du coup, c'est comme ce qu'on voit sur Jupiter, ce qui est intéressant, je ne sais pas si on peut le voir juste ici, voilà, vous le voyez, ça c'est digne des top de boule-market, hop, le premier high de la distribution, et en mode le dernier high de prise de liquidité, qui est en dessous, hop, des niveaux du RSI, donc, on va c'est ce qu'on appelle une divergence, c'est aussi en mode structure de top. Alors je ne sais pas si sur solana on l'a, on va la regarder en direct ensemble, donc boom, on avait dit prise de liquidité juste ici, je m'attends à oc OS juste là, hop, donc faudra voir si on a le c OS, je vais le mettre comme ça, c OS, et pareil, il a prise de liquidité encore une fois, en mode divergence, encore une fois, comme vous le voyez ici, donc voilà, sur la gade lors du dernier top, c'est pareil, c'est genre le premier pic, il est ultra élevé dans le RSI ici, boom, c'est genre en mode apenne, on est apenne en extrême, et en les gens se disent, il y a encore du mois à la hausse pour la démonique qui joue avec le RSI pour zone d'achat zone de vente. Et voilà, donc c'est même, c'est les mêmes structures pour ma part, c'est exactement les mêmes qu'on avait identifié sur nos tramiits injectifs, sur injectifs, c'est celle-là, et d'ailleurs, bien en fait, sur injectifs au final, ce qu'on avait identifié ici en tant que réaccumulation, bien ok, c'est un réaccumulé, certes, on a eu le mouvement aussi, on a récupéré la tière, mais derrière, on s'est retourné, donc heureusement qu'on a la stratégie qui nous permet de gérer le stop loss, etc, etc. Ici, bah, heureusement qu'on avait aussi, on attendait le COS, on n'a pas cassé le COS, donc on n'a pas eu la confirmation de cette accumulation, vraiment tout un sens dans la stratégie, d'ailleurs, vous pouvez apprendre dans la description, vous avez le lien pour Jean de l'école, et pour ceux qui veulent aussi les analyses. Donc voilà, juste après d'ailleurs, je vais faire leur rap, je vais faire le rapport sur la valeur solana pour les gens qui sont dans le groupe, les signaux, mais aussi pour les élèves de l'école. Bref, en gros, c'est à peu près la même solution, la même structure. Donc, sur Injective, elle est beaucoup plus cline, OK ? Donc elle est cool, mais pareil, c'est le même truc RSI qui est manipulé, plus petit que l'autre, blah, blah, blah, blah. Elle mène un retracement, et là, sur Injective, au final, exactement comme ce qu'on a fait à la hausse, le refait à la baisse, donc pour l'instant, bon, il faudra avoir les clôtures mensuelles, je dis qu'avant d'avoir des conclusions, mais là, pour ma part, ça c'est baissier de voir ça sur notre aiminjective, et pour moi, du coup, on va venir combler un peu plus la EVG, je vais même revenir ici pour moi pour chercher une prochaine zone de rebond. La prochaine zone de support sera là sur Injective, autour des $10, donc il va causer un retracement encore plus profond. Et là, par ailleurs, on était sur une simple prise de liquidité, qui amène de la velocité vendue simplement, donc encore une fois, structure de top. Donc, c'était pareil aussi sur Métis, sur GAN METIS USD, ce qu'on voit sur ce l'analyle actuel, pareil, au final, sur Métis, on avait la distribution, donc voilà, pareil, elle est pas clean, un peu comme sur ce l'analyle, mais bon, on sait qu'on a beaucoup de liquidité. Final, on a bien, bien, bien retracé. Je pense qu'on a eu un espèce de pâtaire de accumulation. Maintenant, il faut observer, qu'on a retracé littéralement toute la hausse. Donc, donc voilà, on est dans les dernières zones, pour ma part, j'attenderai des jolis CTAs pour avoir décidé de me repositionner. Mais voilà, voilà. En gros, vous avez compris le topo, pour ma part sur Solana, c'est topiche, la structure qu'on a là. Je m'attends du coup, en cas de cassures des 178$ d'une fin de rallye aussi, et temporaire sur Solana. Et je t'entraie une exposition du coup à Solana, quand qu'à d'accumulation et pas en mode, je recharge Solana parce que c'est bouli, c'est Trump, c'est, je sais pas quoi. Parce que là, pour le coup, il y a, c'est pas trop les signaux envoyés. Et du coup, ça collerait aussi avec un scénario sur Ethereum, qui nous indiqueraient du coup qu'on revient sous ces niveaux-là, tout simplement. Donc voilà. Mais dans tous lesquels, en prochaines vidéos, je vous parle du scénario Bérich, qu'on pourrait avoir sur les marchés. Mais voilà, je voulais vous faire du coup ceci, petit topo sur Solana, pour moi, en cas de cas sur de cette accumulation, c'est signal de top, en tout cas, local, jusqu'au bout le run, je ne sais pas. Mais voilà, en fait, vous l'avez remarqué, de plus en plus, les alcues, une bouge de la manière. Donc, mes tissa ils sont rallyes aussi, ils a eu son top. Donc pour l'enquête d'autres, on a performé, lui, il a fait que son top, etc., etc. À bref, vous avez compris un peu... La globalité des choses. Donc, il n'y a rien de dramatique, je dirais même que ça nous offrira des opportunités. En tout cas, je rêve dans Solana aussi bas. Ça me frappelés. Ça me frappelésir. Donc, voilà. Près bien sûr. Après, en cas de cas sur d'ici, ça se trouve un, on va juste trouver support dans cette grosse dimaine de là. Mais bon. En tout cas, on sait très bien qu'on aura un flush. Si ce n'est pas maintenant, on aura un flush. Donc pour moi, qu'assure, ça pour entraîner un flush de celui-là, celui-là, celui-là, celui-là, celui-là, celui-là, voire même celui-là, jusqu'ici. Donc, au verral, jusqu'à où on s'arrêtera. Mais voilà. C'est un peu la globalité. Des choses et de ce que je vois à la rétuel. Non, voilà, voilà. La vidéo touche ça, ça fin. N'oubliez pas de vous abonner, de nous rejoindre et à très très vite. C'est un peu plus. C'est un peu plus. C'est un peu plus. C'est un peu plus. C'est un peu plus. C'est un peu plus. C'est un peu plus. C'est un peu plus. C'est un peu plus. C'est un peu plus. C'est un peu plus. C'est un peu plus. C'est un peu plus. C'est un peu plus. C'est un peu plus. C'est un peu plus. C'est un peu plus. C'est un peu plus. C'est un peu plus. C'est un peu plus. C'est un peu plus. C'est un peu plus. C'est un peu plus. C'est un peu plus.\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
